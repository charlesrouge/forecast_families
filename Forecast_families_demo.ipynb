{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast families: how to generate and visualize them.\n",
    "Use this notebook to generate and visualize forecast families, as introduced in the following paper submitted to Journal of Water Resources Planning and Management:\n",
    "C. Rougé, A. Peñuela, F. Pianosi. Forecast families: systematic evaluation of benefits from improving the skill of an existing forecast.\n",
    "\n",
    "Note the code is demonstrated directly on the bias corrected rainfall forecast (hindcast) for the 1 November 2011, and contained in file `data/example/ECMWF_bias_corr_20111101.csv`.\n",
    "\n",
    "More forecast data, and the methodology to bias correct these forecasts, is available with the iRONS toolbox at the address `https://github.com/iRONStoolbox/iRONStoolbox` (see also Peñuela et al., 2021 at doi:10.1016/j.envsoft.2021.105188). \n",
    "\n",
    "This is also where we start, by importing the climate data corresponding to the forecast.\n",
    "\n",
    "First, all external library imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dataclasses import make_dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: produce a forecast family and visualise it\n",
    "We use the example forecast contained in file `data/example/ECMWF_bias_corr_20111101.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the forecast family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# Define the skills: from 0 (benchmark) to 1 (perfect forecast) with 0.2 increments.\n",
    "# Specifications also used for plotting (skill data frame)\n",
    "Skill_spec = make_dataclass(\"Skill_spec\", [('value',float), ('stringvalue',str), ('color', str), ('linestyle', str)])\n",
    "skill_specs = pd.DataFrame([\n",
    "    Skill_spec(0, str(\"{:1.1f}\".format(0)), 'k', 'solid'),\n",
    "    Skill_spec(0.2, str(\"{:1.1f}\".format(0.2)), 'k', 'dashed'),\n",
    "    Skill_spec(0.4, str(\"{:1.1f}\".format(0.4)), 'k', 'dotted'),\n",
    "    Skill_spec(0.6, str(\"{:1.1f}\".format(0.6)), 'b', 'solid'),\n",
    "    Skill_spec(0.8, str(\"{:1.1f}\".format(0.8)), 'b', 'dashed'),\n",
    "    Skill_spec(1, str(\"{:1.1f}\".format(1)), 'b', 'dotted')\n",
    "])\n",
    "\n",
    "# Display skill values\n",
    "print(skill_specs['value'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import weather data\n",
    "We get that data for the same site (in SW England) as for the paper. We get it from the Github site for iRONS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 PET       Rain      Temp\n",
      "Date                                     \n",
      "01/01/1980  0.166398   0.000000 -0.809513\n",
      "02/01/1980  0.365613   1.859602 -0.680378\n",
      "03/01/1980  0.000000  11.534853  2.177372\n",
      "04/01/1980  0.414094   5.383545  4.559046\n",
      "05/01/1980  0.215212   1.287237  2.840470\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "url = 'https://github.com/iRONStoolbox/iRONStoolbox/blob/master/iRONS/Notebooks/B%20-%20Implementation/Inputs/hist_clim_data.csv?raw=true'\n",
    "data = pd.read_csv(url, index_col=0)\n",
    "\n",
    "# Check it (see printed result below)\n",
    "print(data.head(5))\n",
    "\n",
    "# Save it\n",
    "data.to_csv('data/hist_clim_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare weather and forecast data\n",
    "This includes:\n",
    "(1) Loading forecast data\n",
    "(2) Loading observations and formatting them to be consistent with the forecast data (extract right variable, correct range of dates, convert data format).\n",
    "\n",
    "Here we use the example of precipitation, called 'Rain' in both observation and forecast data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read forecast and make sure date column is read as datetime objects in Pandas.\n",
    "benchmark_forecast = pd.read_csv('data/example/ECMWF_bias_corr_20111101.csv', index_col=0)\n",
    "benchmark_forecast.index = pd.to_datetime(np.array(benchmark_forecast.index), format='%Y/%m/%d')\n",
    "\n",
    "# Read historical data\n",
    "hist_data = pd.read_csv('data/hist_clim_data.csv', index_col=0)\n",
    "hist_data.index = pd.to_datetime(np.array(hist_data.index), format='%d/%m/%Y')\n",
    "\n",
    "# Get the historical data that corresponds to the forecast period\n",
    "observations = pd.Series(hist_data.loc[benchmark_forecast.index]['Rain'])\n",
    "\n",
    "# Rainfall is cumulative in the forecast, not in the observations: need for formatting.\n",
    "observations = observations.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ensemble family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ensemble import generate_family\n",
    "\n",
    "# Create output folders\n",
    "if os.path.exists('example_results') is False:\n",
    "    os.mkdir('example_results')\n",
    "if os.path.exists('example_results/ensemble_family') is False:\n",
    "    os.mkdir('example_results/ensemble_family')\n",
    "    \n",
    "\n",
    "# Call function to generate family\n",
    "generate_family(observations=observations, \n",
    "                forecast_ensemble=benchmark_forecast, \n",
    "                skill_values=skill_specs['value'].values, \n",
    "                family_folder='example_results/ensemble_family', \n",
    "                different_folders=False, \n",
    "                output_filename='Forecast'\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ensemble family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/example/ECMWF_bias_corr_20111101.csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18800\\99445374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mskill_specs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskill_specs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mvar_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Rain'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mdestination\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'example_results/ensemble_family/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m            )\n",
      "\u001b[1;32m~\\PycharmProjects\\Forecast-based_resilience\\forecast_family\\src\\ensemble.py\u001b[0m in \u001b[0;36mplot_family\u001b[1;34m(hist_file, forecast_path, family_path, skill_specs, var_name, destination)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Read original forecast (which is also the zero-skill family member)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mbenchmark_forecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mbenchmark_forecast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbenchmark_forecast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y/%m/%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     benchmark_stats = pd.DataFrame({'min': benchmark_forecast.min(axis=1),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/example/ECMWF_bias_corr_20111101.csv.csv'"
     ]
    }
   ],
   "source": [
    "from src.ensemble import plot_family\n",
    "\n",
    "plot_family(hist_file='data/hist_clim_data.csv',\n",
    "            forecast_path='data/example/ECMWF_bias_corr_20111101.csv',\n",
    "            family_path=['example_results/ensemble_family/Forecast_', ''],\n",
    "            skill_specs=skill_specs,\n",
    "            var_name='Rain',\n",
    "            destination='example_results/ensemble_family/'\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: generate forecast families for ECMWF data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# Define data range: for instance, winter 2011-2012\n",
    "begin_date = '2011/11/01'\n",
    "end_date = '2012/03/01'\n",
    "\n",
    "# List of skills to consider\n",
    "skill_values = skill_specs['value'].values\n",
    "print(skill_values)  # Still from 0 to 1 with 0.2 increments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ECMWF forecast data\n",
    "These are also taken from the iRONS toolbox, which also contains instructions on how to get data directly from the ECMWF website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where to store the forecast data (create it if needed)\n",
    "forecast_folder = 'data/ECMWF forecasts csv/'\n",
    "if os.path.exists(forecast_folder) is False:\n",
    "    os.mkdir(forecast_folder)\n",
    "\n",
    "# List dates for forecasts to pull, here with a monthly frequency\n",
    "date_list = pd.date_range(start=begin_date, end=end_date, freq='MS')\n",
    "\n",
    "# Variables\n",
    "ecmwf_variables = ['Rain', 'Temp', 'Evap']\n",
    " \n",
    "# Get and save forecast for all dates in range\n",
    "for t in date_list:\n",
    "    \n",
    "    # And for all listed variables\n",
    "    for w in range(len(ecmwf_variables)):\n",
    "    \n",
    "        # Get the data\n",
    "        url = 'https://github.com/iRONStoolbox/iRONStoolbox/blob/master/iRONS/Notebooks/B%20-%20Implementation/Inputs/ECMWF%20forecasts%20csv/' + str(10000*t.year + 100*t.month + t.day) + '_1d_7m_ECMWF_' + ecmwf_variables[w] + '.csv?raw=true'\n",
    "        data = pd.read_csv(url, index_col=0)\n",
    "    \n",
    "        # Save it\n",
    "        data.to_csv(forecast_folder + str(10000*t.year + 100*t.month + t.day) + \n",
    "                    '_1d_7m_ECMWF_' + ecmwf_variables[w] + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ensemble families\n",
    "With skill based on CRPSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ensemble import ecmwf_ensemble_family\n",
    "\n",
    "# Destination folder system\n",
    "family_destination = 'families/'\n",
    "if os.path.exists(family_destination) is False:\n",
    "    os.mkdir(family_destination)\n",
    "    \n",
    "# Ensure you have the variable you want with the right name in (1) the observations, and (2) the forecasts (they can be different).\n",
    "variable_names = ['Rain', 'Rain']\n",
    "\n",
    "# Generate ensemble families\n",
    "ecmwf_ensemble_family('data/hist_clim_data.csv', forecast_folder, variable_names, family_destination, skill_values, \n",
    "                      begin_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create deterministic families\n",
    "With skill based either on MAE (mean absolute error) or MSE (mean squared error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deterministic import ecmwf_deterministic_family\n",
    "\n",
    "# Destination folder system\n",
    "if os.path.exists(family_destination + 'deterministic/') is False:\n",
    "    os.mkdir(family_destination + 'deterministic/')\n",
    "    \n",
    "# Generate deterministic family based on MAE\n",
    "ecmwf_deterministic_family('data/hist_clim_data.csv', forecast_folder, variable_names, family_destination + \n",
    "                           '/deterministic/', skill_values, begin_date, end_date, 'MAE')\n",
    "\n",
    "# Generate deterministic family based on MSE\n",
    "ecmwf_deterministic_family('data/hist_clim_data.csv', forecast_folder, variable_names, family_destination + \n",
    "                           '/deterministic/', skill_values, begin_date, end_date, 'MSE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
